# main_advanced.py - Vers√£o avan√ßada com conex√£o PostgreSQL e logs melhorados

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
import warnings
warnings.filterwarnings('ignore')

# Configura√ß√µes
from config import *
from technical_indicators import add_technical_indicators, add_lagged_features, add_rolling_statistics

# Fun√ß√£o utilit√°ria para monitoramento
def show_system_stats():
    """
    Mostra estat√≠sticas b√°sicas do sistema durante processamento
    """
    import os
    import gc
    
    # For√ßa coleta de lixo
    gc.collect()
    
    # Informa√ß√µes b√°sicas
    print(f"   üêç PID do processo: {os.getpid()}")
    print(f"   üìä Status: Processando...")

# Importa√ß√£o do DatabaseManager com tratamento de erro
try:
    from database import DatabaseManager
    DATABASE_AVAILABLE = True
    print("‚úÖ DatabaseManager carregado com sucesso")
except ImportError as e:
    print(f"‚ö†Ô∏è DatabaseManager n√£o dispon√≠vel: {e}")
    DATABASE_AVAILABLE = False
    DatabaseManager = None
except Exception as e:
    print(f"‚ö†Ô∏è Erro ao carregar DatabaseManager: {e}")
    DATABASE_AVAILABLE = False
    DatabaseManager = None

# Imports do TensorFlow (otimizado para Mac M1 Max com GPU Metal)
try:
    import os
    # Configura√ß√µes otimizadas para Mac M1 Max
    os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  # Reduz logs do TensorFlow
    os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'  # Desabilita oneDNN 
    # Configura√ß√µes para aproveitar m√∫ltiplos cores do M1 Max
    os.environ['OMP_NUM_THREADS'] = '8'  # Aumentado para aproveitar M1 Max (8 performance cores)
    os.environ['TF_NUM_INTEROP_THREADS'] = '8'  # Otimizado para M1 Max
    os.environ['TF_NUM_INTRAOP_THREADS'] = '8'  # Otimizado para M1 Max
    
    import tensorflow as tf
    
    # Configura√ß√£o otimizada para M1 Max
    tf.config.threading.set_inter_op_parallelism_threads(8)
    tf.config.threading.set_intra_op_parallelism_threads(8)
    
    # Detecta e configura Metal Performance Shaders (GPU) no Mac M1 Max
    print("üîç Detectando dispositivos dispon√≠veis...")
    
    # Lista todos os dispositivos f√≠sicos
    physical_devices = tf.config.list_physical_devices()
    print(f"üì± Dispositivos f√≠sicos encontrados: {len(physical_devices)}")
    for device in physical_devices:
        print(f"   ‚Ä¢ {device}")
    
    # Configura√ß√£o espec√≠fica para GPU Metal (M1 Max)
    try:
        # Verifica se Metal Performance Shaders est√° dispon√≠vel
        gpus = tf.config.list_physical_devices('GPU')
        if gpus:
            print(f"üöÄ GPU Metal detectada: {len(gpus)} dispositivo(s)")
            for i, gpu in enumerate(gpus):
                print(f"   GPU {i}: {gpu}")
                # Habilita crescimento din√¢mico de mem√≥ria para evitar erros
                tf.config.experimental.set_memory_growth(gpu, True)
                # Define GPU como preferencial para opera√ß√µes
                tf.config.set_visible_devices(gpu, 'GPU')
            
            # Testa se a GPU est√° funcionando
            with tf.device('/GPU:0'):
                test_tensor = tf.constant([[1.0, 2.0], [3.0, 4.0]])
                result = tf.reduce_sum(test_tensor)
                print(f"‚úÖ Teste GPU bem-sucedido: {result.numpy()}")
                
            print("üéØ TensorFlow configurado para usar GPU Metal (M1 Max)")
            GPU_AVAILABLE = True
            
        else:
            print("‚ö†Ô∏è GPU Metal n√£o detectada, usando CPU otimizada")
            # Otimiza CPU para M1 Max
            tf.config.set_soft_device_placement(True)
            GPU_AVAILABLE = False
            
    except Exception as gpu_error:
        print(f"‚ö†Ô∏è Erro na configura√ß√£o GPU: {gpu_error}")
        print("üîÑ Continuando com CPU otimizada para M1 Max")
        GPU_AVAILABLE = False
    
    from tensorflow.keras.models import Sequential
    from tensorflow.keras.layers import LSTM, Dense, Dropout, BatchNormalization
    from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint
    from tensorflow.keras.optimizers import Adam
    TENSORFLOW_AVAILABLE = True
    
    if GPU_AVAILABLE:
        print("‚úÖ TensorFlow carregado com GPU Metal (M1 Max) - M√ÅXIMA PERFORMANCE")
    else:
        print("‚úÖ TensorFlow carregado com CPU otimizada (M1 Max)")
        
except ImportError as e:
    print(f"TensorFlow n√£o dispon√≠vel: {e}. Apenas Random Forest ser√° usado.")
    TENSORFLOW_AVAILABLE = False
    GPU_AVAILABLE = False
except ImportError as e:
    print(f"TensorFlow n√£o dispon√≠vel: {e}. Apenas Random Forest ser√° usado.")
    TENSORFLOW_AVAILABLE = False
except Exception as e:
    print(f"Erro ao configurar TensorFlow: {e}. Tentando modo simplificado...")
    try:
        import tensorflow as tf
        from tensorflow.keras.models import Sequential
        from tensorflow.keras.layers import LSTM, Dense, Dropout, BatchNormalization
        from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint
        from tensorflow.keras.optimizers import Adam
        TENSORFLOW_AVAILABLE = True
        print("‚úÖ TensorFlow carregado em modo simplificado")
    except:
        print("‚ùå TensorFlow completamente indispon√≠vel. Apenas Random Forest ser√° usado.")
        TENSORFLOW_AVAILABLE = False

# Imports do sklearn
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.model_selection import RandomizedSearchCV, TimeSeriesSplit

def load_and_preprocess_advanced_data_from_db(config, limit=None):
    """
    Carregamento e pr√©-processamento avan√ßado dos dados do PostgreSQL
    """
    if not DATABASE_AVAILABLE:
        raise Exception("DatabaseManager n√£o est√° dispon√≠vel - problema de compatibilidade com typing_extensions/SQLAlchemy")
    
    print("=== CARREGANDO DADOS DO POSTGRESQL ===")
    
    # Inicializa conex√£o com banco
    db = DatabaseManager()
    
    try:
        # Conecta ao banco
        if not db.connect():
            raise Exception("Falha ao conectar com o banco de dados")
        
        # Obt√©m informa√ß√µes da tabela
        print("Verificando estrutura da tabela...")
        db.get_table_info('botbinance')
        
        # Carrega os dados
        print("Carregando dados da tabela botbinance...")
        df = db.load_botbinance_data(limit=limit, order_by='id')
        
        if df is None or len(df) == 0:
            raise Exception("Nenhum dado encontrado na tabela botbinance")
        
        print(f"‚úÖ Dados carregados do banco: {df.shape}")
        print(f"Colunas dispon√≠veis: {list(df.columns)}")
        
        # Verifica se as colunas necess√°rias existem
        required_columns = ['close', 'open', 'high', 'low']
        missing_columns = [col for col in required_columns if col not in df.columns]
        
        if missing_columns:
            print(f"‚ö†Ô∏è Colunas obrigat√≥rias n√£o encontradas: {missing_columns}")
            # Tenta mapear colunas com nomes similares
            column_mapping = {}
            for col in missing_columns:
                similar_cols = [c for c in df.columns if col.lower() in c.lower()]
                if similar_cols:
                    column_mapping[similar_cols[0]] = col
                    print(f"Mapeando {similar_cols[0]} -> {col}")
            
            if column_mapping:
                df = df.rename(columns=column_mapping)
        
        # Adiciona indicadores t√©cnicos
        print("Calculando indicadores t√©cnicos...")
        df = add_technical_indicators(df, TECHNICAL_FEATURES)
        
        # Adiciona features com lag
        print("Adicionando features com lag...")
        base_columns = ['close', 'open', 'high', 'low']
        if 'volume' in df.columns:
            base_columns.append('volume')
        df = add_lagged_features(df, base_columns, lags=[1, 2, 3, 5])
        
        # Adiciona estat√≠sticas rolantes
        print("Calculando estat√≠sticas rolantes...")
        df = add_rolling_statistics(df, ['close'], windows=[5, 10, 20])
        
        # Remove NaN
        initial_rows = len(df)
        df = df.dropna()
        removed_rows = initial_rows - len(df)
        print(f"Removidas {removed_rows} linhas com NaN")
        print(f"Dataset final: {df.shape}")
        
        # Seleciona features para o modelo (exclui colunas de ID e timestamp)
        exclude_columns = ['id', 'created_at', 'updated_at', 'timestamp']
        feature_columns = [col for col in df.columns if col not in exclude_columns]
        
        print(f"Features selecionadas: {len(feature_columns)}")
        print(f"Primeiras 10 features: {feature_columns[:10]}")
        
        return df, feature_columns
        
    except Exception as e:
        print(f"‚ùå Erro ao carregar dados do banco: {e}")
        raise
    finally:
        # Sempre fecha a conex√£o
        db.disconnect()

def load_and_preprocess_advanced_data_from_csv(file_path, config):
    """
    Fun√ß√£o original para carregar dados do CSV (mantida como fallback)
    """
    print("=== CARREGANDO DADOS DO CSV (FALLBACK) ===")
    df = pd.read_csv(file_path, delimiter=';')
    
    print(f"Dataset original: {df.shape}")
    print(f"Colunas dispon√≠veis: {list(df.columns)}")
    
    # Adiciona indicadores t√©cnicos
    print("Calculando indicadores t√©cnicos...")
    df = add_technical_indicators(df, TECHNICAL_FEATURES)
    
    # Adiciona features com lag
    print("Adicionando features com lag...")
    base_columns = ['close', 'open', 'high', 'low']
    if 'volume' in df.columns:
        base_columns.append('volume')
    df = add_lagged_features(df, base_columns, lags=[1, 2, 3, 5])
    
    # Adiciona estat√≠sticas rolantes
    print("Calculando estat√≠sticas rolantes...")
    df = add_rolling_statistics(df, ['close'], windows=[5, 10, 20])
    
    # Remove NaN
    df = df.dropna()
    print(f"Dataset ap√≥s processamento: {df.shape}")
    
    # Seleciona features para o modelo
    feature_columns = [col for col in df.columns if col not in ['id', 'created_at']]
    
    print(f"Features selecionadas: {len(feature_columns)}")
    
    return df, feature_columns

def create_sequences_advanced(data, target_col_idx, seq_length):
    """
    Cria sequ√™ncias para modelos de s√©ries temporais
    """
    X, y = [], []
    for i in range(seq_length, len(data)):
        X.append(data[i-seq_length:i])
        y.append(data[i, target_col_idx])
    
    return np.array(X), np.array(y)

def train_advanced_lstm_m1_max(X_train, y_train, X_test, y_test, config):
    """
    Treina modelo LSTM otimizado para Mac M1 Max com GPU Metal
    """
    if not TENSORFLOW_AVAILABLE:
        print("TensorFlow n√£o dispon√≠vel, pulando LSTM...")
        return None, None
    
    print("üöÄ Construindo modelo LSTM otimizado para M1 Max...")
    
    # For√ßa uso da GPU se dispon√≠vel
    device_name = "/GPU:0" if GPU_AVAILABLE else "/CPU:0"
    print(f"üéØ Usando dispositivo: {device_name}")
    
    # Habilita precis√£o mista se configurado
    if config.get('use_mixed_precision', False) and GPU_AVAILABLE:
        try:
            from tensorflow.keras import mixed_precision
            policy = mixed_precision.Policy('mixed_float16')
            mixed_precision.set_global_policy(policy)
            print("‚úÖ Precis√£o mista habilitada (mixed_float16)")
        except Exception as e:
            print(f"‚ö†Ô∏è N√£o foi poss√≠vel habilitar precis√£o mista: {e}")
    
    # Constr√≥i modelo dentro do contexto do dispositivo
    with tf.device(device_name):
        model = Sequential()
        
        # Primeira camada LSTM otimizada
        model.add(LSTM(
            config['layers'][0], 
            return_sequences=len(config['layers']) > 1,
            input_shape=(X_train.shape[1], X_train.shape[2]),
            # Otimiza√ß√µes para Metal
            activation='tanh',  # Otimizado para Metal
            recurrent_activation='sigmoid',
            dropout=0.0,  # Dropout manual para melhor controle
            recurrent_dropout=0.0,
            implementation=2  # Implementa√ß√£o otimizada
        ))
        model.add(Dropout(config['dropout_rates'][0]))
        
        # Camadas LSTM intermedi√°rias
        for i in range(1, len(config['layers'])):
            return_seq = i < len(config['layers']) - 1
            model.add(LSTM(
                config['layers'][i], 
                return_sequences=return_seq,
                activation='tanh',
                recurrent_activation='sigmoid',
                dropout=0.0,
                recurrent_dropout=0.0,
                implementation=2
            ))
            model.add(Dropout(config['dropout_rates'][i]))
        
        # Camadas densas otimizadas
        for j, dense_size in enumerate(config['dense_layers']):
            model.add(Dense(
                dense_size, 
                activation='relu',
                kernel_initializer='he_normal'  # Melhor para ReLU
            ))
            model.add(Dropout(0.2))
        
        # Camada de sa√≠da
        if config.get('use_mixed_precision', False):
            # Para precis√£o mista, usa float32 na sa√≠da
            model.add(Dense(1, dtype='float32'))
        else:
            model.add(Dense(1))
    
    print(f"üèóÔ∏è Modelo constru√≠do com {model.count_params():,} par√¢metros")
    
    # Compila√ß√£o otimizada para M1 Max
    with tf.device(device_name):
        optimizer = Adam(
            learning_rate=config['learning_rate'],
            clipnorm=config.get('clipnorm', 1.0),
            # Otimiza√ß√µes espec√≠ficas para Metal
            amsgrad=False,  # Desabilita AMSGrad para velocidade
        )
        
        # Loss function otimizada
        loss_function = config.get('loss_function', 'mse')
        if config.get('use_mixed_precision', False):
            # Para precis√£o mista, usa loss scaling
            optimizer = mixed_precision.LossScaleOptimizer(optimizer)
        
        model.compile(
            optimizer=optimizer, 
            loss=loss_function, 
            metrics=['mae']
        )
    
    print("üéØ Modelo compilado para M1 Max")
    print("üìä Arquitetura do modelo:")
    model.summary()
    
    # Callbacks otimizados para M1 Max
    callbacks = [
        EarlyStopping(
            monitor='val_loss',
            patience=config['patience_early_stop'],
            restore_best_weights=True,
            verbose=1
        ),
        ReduceLROnPlateau(
            monitor='val_loss',
            factor=config['reduce_lr_factor'],
            patience=config['patience_reduce_lr'],
            min_lr=config['min_lr'],
            verbose=1
        )
    ]
    
    # Adiciona ModelCheckpoint se especificado
    if config.get('save_best_model', True):
        callbacks.append(ModelCheckpoint(
            'models/best_lstm_m1_max.h5',
            monitor='val_loss',
            save_best_only=True,
            verbose=1
        ))
    
    print(f"üöÄ Iniciando treinamento M1 Max:")
    print(f"   ‚Ä¢ √âpocas: {config['epochs']}")
    print(f"   ‚Ä¢ Batch Size: {config['batch_size']}")
    print(f"   ‚Ä¢ Dispositivo: {device_name}")
    print(f"   ‚Ä¢ Precis√£o Mista: {config.get('use_mixed_precision', False)}")
    
    # Treinamento otimizado
    try:
        with tf.device(device_name):
            history = model.fit(
                X_train, y_train,
                epochs=config['epochs'],
                batch_size=config['batch_size'],
                validation_data=(X_test, y_test),
                callbacks=callbacks,
                verbose=1,
                # Otimiza√ß√µes para M1 Max
                use_multiprocessing=True,
                workers=4,  # Aproveita cores do M1 Max
                max_queue_size=20  # Buffer maior para GPU
            )
        
        print(f"‚úÖ Treinamento M1 Max conclu√≠do em {len(history.history['loss'])} √©pocas")
        print(f"üìà Loss final: {history.history['loss'][-1]:.6f}")
        print(f"üìâ Val Loss final: {history.history['val_loss'][-1]:.6f}")
        
        return model, history
        
    except Exception as e:
        print(f"‚ùå Erro no treinamento M1 Max: {e}")
        print("üîÑ Tentando fallback para CPU...")
        
        # Fallback para CPU
        return train_advanced_lstm(X_train, y_train, X_test, y_test, config)

def train_advanced_lstm(X_train, y_train, X_test, y_test, config):
    """
    Treina modelo LSTM com arquitetura avan√ßada (vers√£o original mantida)
    """
    if not TENSORFLOW_AVAILABLE:
        print("TensorFlow n√£o dispon√≠vel, pulando LSTM...")
        return None, None
    
    # Se M1 Max detectado e GPU dispon√≠vel, usa vers√£o otimizada
    if GPU_AVAILABLE and hasattr(config, 'get') and config.get('force_gpu', False):
        return train_advanced_lstm_m1_max(X_train, y_train, X_test, y_test, config)
    
    print("Construindo modelo LSTM avan√ßado...")
    
    model = Sequential()
    
    # Primeira camada LSTM
    model.add(LSTM(
        config['layers'][0], 
        return_sequences=True, 
        input_shape=(X_train.shape[1], X_train.shape[2])
    ))
    model.add(BatchNormalization())
    model.add(Dropout(config['dropout_rates'][0]))
    
    # Camadas LSTM intermedi√°rias
    for i in range(1, len(config['layers'])-1):
        model.add(LSTM(config['layers'][i], return_sequences=True))
        model.add(BatchNormalization())
        model.add(Dropout(config['dropout_rates'][i]))
    
    # √öltima camada LSTM
    model.add(LSTM(config['layers'][-1]))
    model.add(BatchNormalization())
    model.add(Dropout(config['dropout_rates'][-1]))
    
    # Camadas densas
    for dense_size in config['dense_layers']:
        model.add(Dense(dense_size, activation='relu'))
        model.add(BatchNormalization())
        model.add(Dropout(0.2))
    
    # Camada de sa√≠da
    model.add(Dense(1))
    
    # Compila√ß√£o
    optimizer = Adam(learning_rate=config['learning_rate'])
    model.compile(optimizer=optimizer, loss=config['loss_function'], metrics=['mae'])
    
    print("Arquitetura do modelo:")
    model.summary()
    
    # Callbacks
    callbacks = [
        EarlyStopping(
            monitor='val_loss',
            patience=config['patience_early_stop'],
            restore_best_weights=True,
            verbose=1
        ),
        ReduceLROnPlateau(
            monitor='val_loss',
            factor=0.5,
            patience=config['patience_reduce_lr'],
            min_lr=0.0001,
            verbose=1
        ),
        ModelCheckpoint(
            'models/best_lstm_model.h5',  # Mudando para formato .h5 para compatibilidade
            monitor='val_loss',
            save_best_only=True,
            verbose=1
        )
    ]
    
    # Treinamento
    print("Iniciando treinamento do LSTM...")
    history = model.fit(
        X_train, y_train,
        epochs=config['epochs'],
        batch_size=config['batch_size'],
        validation_data=(X_test, y_test),
        callbacks=callbacks,
        verbose=1
    )
    
    return model, history

def train_ensemble_models(X_train, y_train, quick_mode=False):
    """
    Treina m√∫ltiplos modelos para ensemble com logs detalhados
    """
    import time
    import threading
    import sys
    from datetime import datetime
    
    X_train_flat = X_train.reshape(X_train.shape[0], -1)
    print(f"üìä Dados achatados para modelos tradicionais: {X_train_flat.shape}")
    
    models = {}
    
    # Configura par√¢metros baseado no modo
    if quick_mode:
        print("‚ö° MODO R√ÅPIDO ATIVADO - Menos itera√ß√µes para teste")
        rf_iterations = 10  # Reduzido de 200
        rf_cv_folds = 3     # Reduzido de 7
        gb_iterations = 5   # Reduzido de 30
        gb_cv_folds = 2     # Reduzido de 3
    else:
        print("üéØ MODO COMPLETO - Busca completa de hiperpar√¢metros")
        rf_iterations = RF_CONFIG['random_search_iterations']
        rf_cv_folds = RF_CONFIG['cv_folds']
        gb_iterations = 30
        gb_cv_folds = 3
    
    # Random Forest
    print(f"\nüå≤ === INICIANDO TREINAMENTO RANDOM FOREST ===")
    print(f"‚è∞ In√≠cio: {datetime.now().strftime('%H:%M:%S')}")
    print(f"üîß Modo: {'R√ÅPIDO' if quick_mode else 'COMPLETO'}")
    
    rf_param_dist = {
        'n_estimators': RF_CONFIG['n_estimators_options'],
        'max_depth': RF_CONFIG['max_depth_options'],
        'min_samples_split': RF_CONFIG['min_samples_split_options'],
        'min_samples_leaf': RF_CONFIG['min_samples_leaf_options'],
        'max_features': RF_CONFIG['max_features_options']
    }
    
    print(f"üîß Par√¢metros para busca:")
    for param, values in rf_param_dist.items():
        print(f"   {param}: {values}")
    
    total_combinations = rf_iterations * rf_cv_folds
    print(f"üîç Testando {rf_iterations} combina√ß√µes com {rf_cv_folds} folds")
    print(f"üìà Total de fits: {total_combinations}")
    estimated_time = total_combinations * 2  # Estimativa de 2 segundos por fit
    print(f"‚è±Ô∏è  Tempo estimado: {estimated_time/60:.1f} minutos")
    print("üí° Aguarde o processamento...")
    
    start_time = time.time()
    
    rf = RandomForestRegressor(random_state=42, n_jobs=-1)
    rf_search = RandomizedSearchCV(
        rf, rf_param_dist, 
        n_iter=rf_iterations,
        cv=TimeSeriesSplit(n_splits=rf_cv_folds),
        scoring='neg_mean_squared_error',
        n_jobs=-1,
        verbose=2  # Aumentado para mais detalhes
    )
    
    print("üöÄ Iniciando busca de hiperpar√¢metros...")
    
    # Monitor de progresso para RF
    def progress_monitor():
        start = time.time()
        counter = 0
        while not hasattr(progress_monitor, 'stop'):
            time.sleep(45)  # Aguarda 45 segundos
            if not hasattr(progress_monitor, 'stop'):
                counter += 1
                elapsed = time.time() - start
                print(f"   üîÑ Random Forest ainda processando... {elapsed:.0f}s ({elapsed/60:.1f} min) - Update #{counter}")
                show_system_stats()
                sys.stdout.flush()
    
    # Inicia monitor em thread separada
    monitor_thread = threading.Thread(target=progress_monitor, daemon=True)
    monitor_thread.start()
    
    try:
        rf_search.fit(X_train_flat, y_train)
    finally:
        # Para o monitor
        progress_monitor.stop = True
    
    rf_time = time.time() - start_time
    print(f"‚úÖ Random Forest conclu√≠do!")
    print(f"‚è±Ô∏è  Tempo decorrido: {rf_time:.1f} segundos ({rf_time/60:.1f} minutos)")
    print(f"üèÜ Melhor score: {rf_search.best_score_:.6f}")
    print(f"üîß Melhores par√¢metros:")
    for param, value in rf_search.best_params_.items():
        print(f"   {param}: {value}")
    
    models['rf'] = rf_search.best_estimator_
    
    # Gradient Boosting
    print(f"\nüöÄ === INICIANDO TREINAMENTO GRADIENT BOOSTING ===")
    print(f"‚è∞ In√≠cio: {datetime.now().strftime('%H:%M:%S')}")
    
    gb_param_dist = {
        'n_estimators': [100, 200, 300],
        'learning_rate': [0.01, 0.1, 0.2],
        'max_depth': [3, 5, 7],
        'subsample': [0.8, 0.9, 1.0],
        'max_features': ['sqrt', 'log2', None]
    }
    
    print(f"üîß Par√¢metros para busca:")
    for param, values in gb_param_dist.items():
        print(f"   {param}: {values}")
    
    gb_total_combinations = gb_iterations * gb_cv_folds
    print(f"üîç Testando {gb_iterations} combina√ß√µes com {gb_cv_folds} folds")
    print(f"üìà Total de fits: {gb_total_combinations}")
    gb_estimated_time = gb_total_combinations * 3  # Estimativa de 3 segundos por fit
    print(f"‚è±Ô∏è  Tempo estimado: {gb_estimated_time/60:.1f} minutos")
    print("üí° Processando Gradient Boosting...")
    
    start_time = time.time()
    
    gb = GradientBoostingRegressor(random_state=42)
    gb_search = RandomizedSearchCV(
        gb, gb_param_dist,
        n_iter=gb_iterations,
        cv=TimeSeriesSplit(n_splits=gb_cv_folds),
        scoring='neg_mean_squared_error',
        n_jobs=-1,
        verbose=2  # Aumentado para mais detalhes
    )
    
    print("üöÄ Iniciando busca de hiperpar√¢metros GB...")
    
    # Monitor de progresso para GB
    def progress_monitor_gb():
        start = time.time()
        counter = 0
        while not hasattr(progress_monitor_gb, 'stop'):
            time.sleep(30)  # Aguarda 30 segundos
            if not hasattr(progress_monitor_gb, 'stop'):
                counter += 1
                elapsed = time.time() - start
                print(f"   üîÑ Gradient Boosting ainda processando... {elapsed:.0f}s ({elapsed/60:.1f} min) - Update #{counter}")
                show_system_stats()
                sys.stdout.flush()
    
    # Inicia monitor em thread separada
    monitor_thread_gb = threading.Thread(target=progress_monitor_gb, daemon=True)
    monitor_thread_gb.start()
    
    try:
        gb_search.fit(X_train_flat, y_train)
    finally:
        # Para o monitor
        progress_monitor_gb.stop = True
    
    gb_time = time.time() - start_time
    print(f"‚úÖ Gradient Boosting conclu√≠do!")
    print(f"‚è±Ô∏è  Tempo decorrido: {gb_time:.1f} segundos ({gb_time/60:.1f} minutos)")
    print(f"üèÜ Melhor score: {gb_search.best_score_:.6f}")
    print(f"üîß Melhores par√¢metros:")
    for param, value in gb_search.best_params_.items():
        print(f"   {param}: {value}")
    
    models['gb'] = gb_search.best_estimator_
    
    print(f"\nüéâ === ENSEMBLE TREINAMENTO CONCLU√çDO ===")
    print(f"‚úÖ Modelos treinados: {list(models.keys())}")
    total_time = rf_time + gb_time
    print(f"‚è±Ô∏è  Tempo total do ensemble: {total_time:.1f} segundos ({total_time/60:.1f} minutos)")
    
    return models

def calculate_comprehensive_metrics(y_true, y_pred, model_name):
    """
    Calcula m√©tricas abrangentes
    """
    metrics = {
        'Model': model_name,
        'RMSE': np.sqrt(mean_squared_error(y_true, y_pred)),
        'MAE': mean_absolute_error(y_true, y_pred),
        'R¬≤': r2_score(y_true, y_pred),
        'MAPE': np.mean(np.abs((y_true - y_pred) / y_true)) * 100
    }
    
    return metrics

def plot_comprehensive_results(y_test, predictions_dict, history=None):
    """
    Plota resultados abrangentes
    """
    # Configurar estilo
    plt.style.use('seaborn-v0_8')
    
    # Plot 1: Compara√ß√£o de previs√µes
    plt.figure(figsize=(20, 12))
    
    plt.subplot(2, 3, 1)
    plt.plot(y_test, label='Real', color='blue', linewidth=2)
    for name, preds in predictions_dict.items():
        plt.plot(preds, label=name, alpha=0.8)
    plt.title('Compara√ß√£o de Previs√µes')
    plt.legend()
    plt.grid(True, alpha=0.3)
    
    # Plot 2: Erro por modelo
    plt.subplot(2, 3, 2)
    errors = {}
    for name, preds in predictions_dict.items():
        errors[name] = np.abs(y_test.flatten() - preds.flatten())
    
    plt.boxplot(errors.values(), labels=errors.keys())
    plt.title('Distribui√ß√£o dos Erros')
    plt.yscale('log')
    plt.xticks(rotation=45)
    
    # Plot 3: Scatter plot - Real vs Previsto
    plt.subplot(2, 3, 3)
    for name, preds in predictions_dict.items():
        plt.scatter(y_test, preds, alpha=0.6, label=name)
    plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)
    plt.xlabel('Valores Reais')
    plt.ylabel('Previs√µes')
    plt.title('Real vs Previsto')
    plt.legend()
    
    # Plot 4: Hist√≥rico de treinamento (se dispon√≠vel)
    if history is not None:
        plt.subplot(2, 3, 4)
        plt.plot(history.history['loss'], label='Treino')
        plt.plot(history.history['val_loss'], label='Valida√ß√£o')
        plt.title('Hist√≥rico de Perda')
        plt.legend()
        plt.yscale('log')
    
    # Plot 5: Residuos
    plt.subplot(2, 3, 5)
    for name, preds in predictions_dict.items():
        residuals = y_test.flatten() - preds.flatten()
        plt.scatter(preds, residuals, alpha=0.6, label=name)
    plt.axhline(y=0, color='r', linestyle='--')
    plt.xlabel('Previs√µes')
    plt.ylabel('Res√≠duos')
    plt.title('An√°lise de Res√≠duos')
    plt.legend()
    
    # Plot 6: √öltimas previs√µes (zoom)
    plt.subplot(2, 3, 6)
    last_points = min(50, len(y_test))
    plt.plot(y_test[-last_points:], label='Real', color='blue', linewidth=2)
    for name, preds in predictions_dict.items():
        plt.plot(preds[-last_points:], label=name, alpha=0.8)
    plt.title('√öltimas 50 Previs√µes')
    plt.legend()
    plt.grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.show()

def save_all_models(lstm_model, ensemble_models, scaler, feature_columns, model_dir='models'):
    """
    Salva todos os modelos treinados e metadados necess√°rios
    """
    import os
    import joblib
    import json
    from datetime import datetime
    
    # Cria diret√≥rio se n√£o existir
    os.makedirs(model_dir, exist_ok=True)
    
    print(f"\nüíæ === SALVANDO MODELOS ===")
    print(f"üìÅ Diret√≥rio: {model_dir}")
    saved_files = []
    
    try:
        # 1. Salva o scaler (ESSENCIAL para desnormaliza√ß√£o)
        scaler_path = os.path.join(model_dir, 'scaler.pkl')
        joblib.dump(scaler, scaler_path)
        saved_files.append(scaler_path)
        print(f"‚úÖ Scaler salvo: {scaler_path}")
        
        # 2. Salva modelos ensemble (Random Forest e Gradient Boosting)
        for name, model in ensemble_models.items():
            model_path = os.path.join(model_dir, f'{name}_model.pkl')
            joblib.dump(model, model_path)
            saved_files.append(model_path)
            print(f"‚úÖ {name.upper()} salvo: {model_path}")
        
        # 3. Modelo LSTM j√° √© salvo automaticamente pelo ModelCheckpoint
        lstm_path = os.path.join(model_dir, 'best_lstm_model.h5')
        if os.path.exists(lstm_path):
            saved_files.append(lstm_path)
            print(f"‚úÖ LSTM j√° salvo: {lstm_path}")
        elif lstm_model is not None:
            # Salva manualmente se n√£o foi salvo pelo callback
            lstm_model.save(lstm_path)
            saved_files.append(lstm_path)
            print(f"‚úÖ LSTM salvo manualmente: {lstm_path}")
        
        # 4. Salva metadados importantes
        metadata = {
            'timestamp': datetime.now().isoformat(),
            'feature_columns': feature_columns,
            'seq_length': SEQ_LENGTH,
            'test_size': TEST_SIZE,
            'models_available': list(ensemble_models.keys()) + (['lstm'] if lstm_model else []),
            'total_features': len(feature_columns),
            'target_column': 'close'
        }
        
        metadata_path = os.path.join(model_dir, 'model_metadata.json')
        with open(metadata_path, 'w') as f:
            json.dump(metadata, f, indent=2)
        saved_files.append(metadata_path)
        print(f"‚úÖ Metadados salvos: {metadata_path}")
        
        # 5. Cria script de carregamento
        loading_script = f"""# Script para carregar os modelos salvos
import joblib
import json
import numpy as np
from tensorflow.keras.models import load_model

# Carrega metadados
with open('{metadata_path}', 'r') as f:
    metadata = json.load(f)

# Carrega scaler
scaler = joblib.load('{scaler_path}')

# Carrega modelos ensemble
ensemble_models = {{}}
"""
        
        for name in ensemble_models.keys():
            loading_script += f"ensemble_models['{name}'] = joblib.load('{model_dir}/{name}_model.pkl')\n"
        
        if lstm_model:
            loading_script += f"""
# Carrega modelo LSTM
lstm_model = load_model('{lstm_path}')

print("‚úÖ Todos os modelos carregados com sucesso!")
print(f"Features dispon√≠veis: {{len(metadata['feature_columns'])}}")
print(f"Modelos carregados: {{metadata['models_available']}}")
"""
        
        script_path = os.path.join(model_dir, 'load_models.py')
        with open(script_path, 'w') as f:
            f.write(loading_script)
        saved_files.append(script_path)
        print(f"‚úÖ Script de carregamento criado: {script_path}")
        
        print(f"\nüéâ Salvamento conclu√≠do!")
        print(f"üìä Total de arquivos salvos: {len(saved_files)}")
        
        # Calcula tamanho total
        total_size = 0
        for file_path in saved_files:
            if os.path.exists(file_path):
                size = os.path.getsize(file_path)
                total_size += size
                print(f"   üìÑ {os.path.basename(file_path)}: {size/1024/1024:.2f} MB")
        
        print(f"üíΩ Tamanho total: {total_size/1024/1024:.2f} MB")
        
        return saved_files
        
    except Exception as e:
        print(f"‚ùå Erro ao salvar modelos: {e}")
        return []

# Fun√ß√£o para carregar modelos salvos
def load_saved_models(model_dir='models'):
    """
    Carrega todos os modelos salvos
    """
    import os
    import joblib
    import json
    
    try:
        # Carrega metadados
        metadata_path = os.path.join(model_dir, 'model_metadata.json')
        with open(metadata_path, 'r') as f:
            metadata = json.load(f)
        
        # Carrega scaler
        scaler_path = os.path.join(model_dir, 'scaler.pkl')
        scaler = joblib.load(scaler_path)
        
        # Carrega modelos ensemble
        ensemble_models = {}
        for name in ['rf', 'gb']:
            model_path = os.path.join(model_dir, f'{name}_model.pkl')
            if os.path.exists(model_path):
                ensemble_models[name] = joblib.load(model_path)
        
        # Carrega LSTM se dispon√≠vel
        lstm_model = None
        lstm_path = os.path.join(model_dir, 'best_lstm_model.h5')
        if os.path.exists(lstm_path):
            try:
                from tensorflow.keras.models import load_model
                lstm_model = load_model(lstm_path)
            except:
                print("‚ö†Ô∏è TensorFlow n√£o dispon√≠vel, LSTM n√£o carregado")
        
        print(f"‚úÖ Modelos carregados de {model_dir}")
        print(f"üìä Features: {len(metadata['feature_columns'])}")
        print(f"ü§ñ Modelos: {metadata['models_available']}")
        
        return {
            'metadata': metadata,
            'scaler': scaler,
            'ensemble_models': ensemble_models,
            'lstm_model': lstm_model
        }
        
    except Exception as e:
        print(f"‚ùå Erro ao carregar modelos: {e}")
        return None

def main():
    """
    Fun√ß√£o principal - Vers√£o com PostgreSQL e logs melhorados
    """
    import time
    from datetime import datetime
    
    print("=== SISTEMA AVAN√áADO DE PREVIS√ÉO COM POSTGRESQL ===")
    print(f"üïê In√≠cio da execu√ß√£o: {datetime.now().strftime('%d/%m/%Y %H:%M:%S')}")
    
    # Configura√ß√£o para fallback CSV
    use_database = DATABASE_AVAILABLE  # S√≥ usa database se estiver dispon√≠vel
    csv_fallback = 'relatorio_mensal_geral_2025-03 (1).csv'
    
    try:
        # Tenta carregar dados do PostgreSQL
        if use_database:
            print("Tentando carregar dados do PostgreSQL...")
            df, feature_columns = load_and_preprocess_advanced_data_from_db(
                TECHNICAL_FEATURES, 
                limit=None  # None = todos os dados, ou especifique um n√∫mero para teste
            )
        else:
            raise Exception("DatabaseManager n√£o dispon√≠vel - usando CSV")
            
    except Exception as e:
        print(f"‚ö†Ô∏è Erro ao carregar do PostgreSQL: {e}")
        print("Tentando fallback para CSV...")
        
        try:
            df, feature_columns = load_and_preprocess_advanced_data_from_csv(
                csv_fallback, 
                TECHNICAL_FEATURES
            )
            print("‚úÖ Dados carregados do CSV com sucesso")
        except Exception as csv_error:
            print(f"‚ùå Erro tamb√©m no CSV: {csv_error}")
            print("Verifique as configura√ß√µes do banco (.env) ou a exist√™ncia do arquivo CSV")
            return
    
    # Prepara dados
    data = df[feature_columns].values
    target_col_idx = feature_columns.index('close')
    
    print(f"\nDados preparados:")
    print(f"Shape dos dados: {data.shape}")
    print(f"√çndice da coluna 'close': {target_col_idx}")
    
    # Normaliza√ß√£o
    scaler = MinMaxScaler()
    data_scaled = scaler.fit_transform(data)
    
    # Cria sequ√™ncias
    X, y = create_sequences_advanced(data_scaled, target_col_idx, SEQ_LENGTH)
    
    # Divis√£o treino/teste
    split_idx = int(len(X) * (1 - TEST_SIZE))
    X_train, X_test = X[:split_idx], X[split_idx:]
    y_train, y_test = y[:split_idx], y[split_idx:]
    
    print(f"Treino: {X_train.shape}, Teste: {X_test.shape}")
    
    # Treina modelos
    predictions = {}
    metrics_list = []
    
    # LSTM
    if TENSORFLOW_AVAILABLE:
        print("\n=== TREINANDO LSTM ===")
        lstm_model, history = train_advanced_lstm(X_train, y_train, X_test, y_test, LSTM_CONFIG)
        if lstm_model is not None:
            lstm_pred = lstm_model.predict(X_test)
            
            # Desnormaliza LSTM
            lstm_pred_full = np.zeros((len(lstm_pred), len(feature_columns)))
            lstm_pred_full[:, target_col_idx] = lstm_pred.flatten()
            lstm_pred_rescaled = scaler.inverse_transform(lstm_pred_full)[:, target_col_idx]
            
            predictions['LSTM'] = lstm_pred_rescaled
    else:
        history = None
        print("‚ö†Ô∏è TensorFlow n√£o dispon√≠vel, LSTM ser√° ignorado")
    
    # Ensemble de modelos tradicionais
    print("\n=== TREINANDO MODELOS ENSEMBLE ===")
    print("ü§ñ Iniciando treinamento de modelos tradicionais (Random Forest + Gradient Boosting)")
    print("‚ö†Ô∏è  IMPORTANTE: Este processo pode levar v√°rios minutos dependendo do tamanho dos dados")
    print(f"üìä Dados de treino: {X_train.shape[0]} amostras com {X_train.shape[1]} timesteps e {X_train.shape[2]} features")
    
    # Pergunta sobre modo r√°pido
    print("\nü§î Escolha o modo de treinamento:")
    print("   1Ô∏è‚É£  COMPLETO: Busca completa de hiperpar√¢metros (mais lento, melhor precis√£o)")
    print("   2Ô∏è‚É£  R√ÅPIDO: Busca reduzida para teste (mais r√°pido, precis√£o OK)")
    
    # Por padr√£o, usar modo r√°pido se muitos dados
    use_quick_mode = len(X_train) > 5000  # Modo r√°pido para datasets grandes
    
    if use_quick_mode:
        print("üöÄ Dataset grande detectado - Usando MODO R√ÅPIDO automaticamente")
        print("   (Para for√ßar modo completo, modifique o c√≥digo)")
    else:
        print("üìä Dataset pequeno/m√©dio - Usando MODO COMPLETO")
    
    ensemble_start_time = time.time()
    ensemble_models = train_ensemble_models(X_train, y_train, quick_mode=use_quick_mode)
    ensemble_total_time = time.time() - ensemble_start_time
    
    print(f"üéØ Ensemble conclu√≠do em {ensemble_total_time:.1f} segundos ({ensemble_total_time/60:.1f} minutos)")
    
    # Desnormaliza y_test
    print("\nüìà === PREPARANDO DADOS PARA AVALIA√á√ÉO ===")
    print("üîÑ Desnormalizando dados de teste...")
    y_test_full = np.zeros((len(y_test), len(feature_columns)))
    y_test_full[:, target_col_idx] = y_test
    y_test_rescaled = scaler.inverse_transform(y_test_full)[:, target_col_idx]
    
    # Previs√µes dos modelos tradicionais
    print("\nüîÆ === FAZENDO PREVIS√ïES ===")
    X_test_flat = X_test.reshape(X_test.shape[0], -1)
    print(f"üìä Dados de teste achatados: {X_test_flat.shape}")
    
    for name, model in ensemble_models.items():
        print(f"üéØ Fazendo previs√µes com {name.upper()}...")
        pred_start = time.time()
        pred = model.predict(X_test_flat)
        pred_time = time.time() - pred_start
        
        pred_full = np.zeros((len(pred), len(feature_columns)))
        pred_full[:, target_col_idx] = pred
        pred_rescaled = scaler.inverse_transform(pred_full)[:, target_col_idx]
        predictions[name.upper()] = pred_rescaled
        
        print(f"   ‚úÖ {name.upper()} conclu√≠do em {pred_time:.2f}s")
        print(f"   üìà Previs√£o m√©dia: {pred_rescaled.mean():.2f}")
        print(f"   üìä Min: {pred_rescaled.min():.2f}, Max: {pred_rescaled.max():.2f}")
    
    # Ensemble final
    if len(predictions) > 1:
        ensemble_pred = np.mean(list(predictions.values()), axis=0)
        predictions['ENSEMBLE'] = ensemble_pred
    
    # Calcula m√©tricas
    print("\n=== CALCULANDO M√âTRICAS ===")
    for name, preds in predictions.items():
        metrics = calculate_comprehensive_metrics(y_test_rescaled, preds, name)
        metrics_list.append(metrics)
    
    # Mostra resultados
    results_df = pd.DataFrame(metrics_list)
    print("\n=== RESULTADOS FINAIS ===")
    print(results_df.round(4))
    
    # Identifica o melhor modelo
    best_model_idx = results_df['RMSE'].idxmin()
    best_model = results_df.loc[best_model_idx, 'Model']
    best_rmse = results_df.loc[best_model_idx, 'RMSE']
    print(f"\nüèÜ Melhor modelo: {best_model} (RMSE: {best_rmse:.4f})")
    
    # Previs√£o do pr√≥ximo valor
    print("\n=== PREVIS√ÉO DO PR√ìXIMO VALOR ===")
    last_sequence = data_scaled[-SEQ_LENGTH:].reshape(1, SEQ_LENGTH, -1)
    
    next_predictions = {}
    
    for name, model in ensemble_models.items():
        if name == 'rf' or name == 'gb':
            next_pred = model.predict(last_sequence.reshape(1, -1))[0]
            next_pred_full = np.zeros((1, len(feature_columns)))
            next_pred_full[0, target_col_idx] = next_pred
            next_pred_rescaled = scaler.inverse_transform(next_pred_full)[0, target_col_idx]
            next_predictions[name.upper()] = next_pred_rescaled
            print(f"{name.upper()}: {next_pred_rescaled:.2f}")
    
    if TENSORFLOW_AVAILABLE and 'lstm_model' in locals():
        lstm_next = lstm_model.predict(last_sequence)[0, 0]
        lstm_next_full = np.zeros((1, len(feature_columns)))
        lstm_next_full[0, target_col_idx] = lstm_next
        lstm_next_rescaled = scaler.inverse_transform(lstm_next_full)[0, target_col_idx]
        next_predictions['LSTM'] = lstm_next_rescaled
        print(f"LSTM: {lstm_next_rescaled:.2f}")
    
    # Ensemble da pr√≥xima previs√£o
    if len(next_predictions) > 1:
        ensemble_next = np.mean(list(next_predictions.values()))
        print(f"ENSEMBLE: {ensemble_next:.2f}")
    
    # Salva todos os modelos
    print("\n=== SALVANDO MODELOS ===")
    lstm_model_to_save = lstm_model if TENSORFLOW_AVAILABLE and 'lstm_model' in locals() else None
    saved_files = save_all_models(
        lstm_model=lstm_model_to_save,
        ensemble_models=ensemble_models,
        scaler=scaler,
        feature_columns=feature_columns
    )
    
    if saved_files:
        print(f"üéØ Modelos salvos com sucesso em: models/")
        print("üìñ Para usar os modelos salvos:")
        print("   1. Execute: from main_advanced import load_saved_models")
        print("   2. models = load_saved_models()")
        print("   3. Ou execute o script: python models/load_models.py")
    
    # Plots
    print("\n=== GERANDO GR√ÅFICOS ===")
    plot_comprehensive_results(y_test_rescaled.reshape(-1, 1), predictions, history)
    
    print("\n=== AN√ÅLISE CONCLU√çDA ===")
    print(f"üïê Fim da execu√ß√£o: {datetime.now().strftime('%d/%m/%Y %H:%M:%S')}")
    print(f"Fonte dos dados: {'PostgreSQL' if use_database else 'CSV'}")
    print(f"Total de features utilizadas: {len(feature_columns)}")
    print(f"Modelos treinados: {list(predictions.keys())}")
    print(f"üìÅ Modelos salvos em: models/ ({len(saved_files)} arquivos)")
    
    return results_df, predictions, next_predictions

# Fun√ß√£o para fazer previs√µes usando modelos salvos
def predict_with_saved_models(new_data, model_dir='models', target_column='close'):
    """
    Faz previs√µes usando modelos salvos
    
    Args:
        new_data: DataFrame com os mesmos indicadores t√©cnicos do treinamento
        model_dir: Diret√≥rio onde est√£o os modelos salvos
        target_column: Nome da coluna target
    
    Returns:
        dict: Previs√µes de cada modelo
    """
    import os
    
    # Carrega modelos
    loaded = load_saved_models(model_dir)
    if loaded is None:
        print("‚ùå N√£o foi poss√≠vel carregar os modelos")
        return None
    
    metadata = loaded['metadata']
    scaler = loaded['scaler']
    ensemble_models = loaded['ensemble_models']
    lstm_model = loaded['lstm_model']
    
    print(f"üîÆ === FAZENDO PREVIS√ïES COM MODELOS SALVOS ===")
    print(f"üìä Dados de entrada: {new_data.shape}")
    
    try:
        # Prepara os dados
        feature_columns = metadata['feature_columns']
        seq_length = metadata['seq_length']
        
        # Verifica se todas as features est√£o presentes
        missing_features = [col for col in feature_columns if col not in new_data.columns]
        if missing_features:
            print(f"‚ö†Ô∏è Features faltando: {missing_features[:5]}...")
            print("Adicionando indicadores t√©cnicos...")
            # Adiciona indicadores t√©cnicos se necess√°rio
            new_data = add_technical_indicators(new_data, feature_columns)
            new_data = add_lagged_features(new_data, ['close', 'open', 'high', 'low'], lags=[1, 2, 3, 5])
            new_data = add_rolling_statistics(new_data, ['close'], windows=[5, 10, 20])
        
        # Seleciona apenas as features do modelo
        data_features = new_data[feature_columns].values
        
        # Normaliza
        data_scaled = scaler.transform(data_features)
        
        predictions = {}
        
        # Previs√µes com modelos ensemble
        if len(ensemble_models) > 0:
            # Para modelos tradicionais, usa apenas o √∫ltimo ponto
            if len(data_scaled) >= seq_length:
                last_sequence = data_scaled[-seq_length:].reshape(1, -1)
                target_idx = feature_columns.index(target_column)
                
                for name, model in ensemble_models.items():
                    pred = model.predict(last_sequence)[0]
                    
                    # Desnormaliza
                    pred_full = np.zeros((1, len(feature_columns)))
                    pred_full[0, target_idx] = pred
                    pred_rescaled = scaler.inverse_transform(pred_full)[0, target_idx]
                    
                    predictions[name.upper()] = pred_rescaled
                    print(f"üéØ {name.upper()}: {pred_rescaled:.2f}")
        
        # Previs√£o com LSTM
        if lstm_model is not None and len(data_scaled) >= seq_length:
            lstm_sequence = data_scaled[-seq_length:].reshape(1, seq_length, -1)
            lstm_pred = lstm_model.predict(lstm_sequence, verbose=0)[0, 0]
            
            # Desnormaliza
            target_idx = feature_columns.index(target_column)
            lstm_pred_full = np.zeros((1, len(feature_columns)))
            lstm_pred_full[0, target_idx] = lstm_pred
            lstm_pred_rescaled = scaler.inverse_transform(lstm_pred_full)[0, target_idx]
            
            predictions['LSTM'] = lstm_pred_rescaled
            print(f"üß† LSTM: {lstm_pred_rescaled:.2f}")
        
        # Ensemble final
        if len(predictions) > 1:
            ensemble_pred = np.mean(list(predictions.values()))
            predictions['ENSEMBLE'] = ensemble_pred
            print(f"üéØ ENSEMBLE: {ensemble_pred:.2f}")
        
        print(f"‚úÖ Previs√µes conclu√≠das!")
        return predictions
        
    except Exception as e:
        print(f"‚ùå Erro ao fazer previs√µes: {e}")
        return None

if __name__ == "__main__":
    main()
