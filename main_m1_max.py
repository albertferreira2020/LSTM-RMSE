#!/usr/bin/env python3
# main_m1_max.py - Vers√£o espec√≠fica otimizada para Mac M1 Max

import pandas as pd
import numpy as np
import time
from datetime import datetime
import warnings
warnings.filterwarnings('ignore')

# Importa configura√ß√µes M1 Max
from config_m1_max import *

def check_m1_max_environment():
    """
    Verifica e configura ambiente M1 Max
    """
    print("üîç === VERIFICANDO AMBIENTE M1 MAX ===")
    
    # Verifica TensorFlow e Metal
    try:
        import tensorflow as tf
        print(f"‚úÖ TensorFlow: {tf.__version__}")
        
        # Verifica Metal
        metal_available, gpus = check_metal_support()
        
        if metal_available:
            print("üöÄ Metal Performance Shaders: DISPON√çVEL")
            print(f"üí™ GPUs detectadas: {len(gpus)}")
            return True
        else:
            print("‚ö†Ô∏è Metal Performance Shaders: N√ÉO DISPON√çVEL")
            print("üîÑ Continuar√° com CPU otimizada")
            return False
            
    except ImportError:
        print("‚ùå TensorFlow n√£o instalado")
        return False

def setup_m1_max_tensorflow():
    """
    Configura TensorFlow especificamente para M1 Max
    """
    try:
        import os
        import tensorflow as tf
        
        # Configura√ß√µes espec√≠ficas M1 Max
        os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'
        os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'
        
        # Aproveita todos os cores do M1 Max
        os.environ['OMP_NUM_THREADS'] = '10'  # 8 performance + 2 efficiency
        os.environ['TF_NUM_INTEROP_THREADS'] = '10'
        os.environ['TF_NUM_INTRAOP_THREADS'] = '10'
        
        # Configura√ß√µes de threading
        tf.config.threading.set_inter_op_parallelism_threads(10)
        tf.config.threading.set_intra_op_parallelism_threads(10)
        
        # Detecta e configura Metal GPU
        gpus = tf.config.list_physical_devices('GPU')
        if gpus:
            print(f"üéØ Configurando {len(gpus)} GPU(s) Metal...")
            for gpu in gpus:
                tf.config.experimental.set_memory_growth(gpu, True)
                
            # Testa GPU
            with tf.device('/GPU:0'):
                test_tensor = tf.constant([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])
                result = tf.reduce_sum(test_tensor)
                print(f"‚úÖ Teste GPU Metal: {result.numpy()}")
                
            return True, gpus
        else:
            print("‚ö†Ô∏è GPU Metal n√£o detectada, usando CPU otimizada")
            return False, []
            
    except Exception as e:
        print(f"‚ùå Erro configurando TensorFlow: {e}")
        return False, []

def run_m1_max_optimized():
    """
    Executa vers√£o otimizada para M1 Max
    """
    print("üöÄ === LSTM-RMSE OTIMIZADO PARA M1 MAX ===")
    print(f"üïê In√≠cio: {datetime.now().strftime('%d/%m/%Y %H:%M:%S')}")
    
    start_time = time.time()
    
    # Verifica ambiente
    metal_available = check_m1_max_environment()
    
    if metal_available:
        print("üí™ Modo: M√ÅXIMA PERFORMANCE (GPU Metal)")
        config_mode = "gpu"
    else:
        print("‚ö° Modo: ALTA PERFORMANCE (CPU M1 Max)")
        config_mode = "cpu"
    
    # Configura TensorFlow
    gpu_available, gpus = setup_m1_max_tensorflow()
    
    try:
        # Carrega dados (usando database manager original)
        print("\nüìä === CARREGANDO DADOS ===")
        from database import DatabaseManager
        
        db = DatabaseManager()
        if not db.connect():
            raise Exception("Falha na conex√£o com banco")
        
        # Carrega dados
        df = db.load_botbinance_data(limit=None, order_by='id')
        data_size = len(df)
        print(f"‚úÖ {data_size} registros carregados")
        
        # Obt√©m configura√ß√£o otimizada para M1 Max
        optimal_config = get_m1_max_optimal_config(data_size, force_gpu=gpu_available)
        
        # Adiciona indicadores t√©cnicos otimizados
        print("üîß Calculando indicadores t√©cnicos...")
        from technical_indicators import add_technical_indicators, add_lagged_features, add_rolling_statistics
        
        df = add_technical_indicators(df, TECHNICAL_FEATURES_M1_MAX)
        
        # Features lag otimizadas
        base_columns = ['close', 'open', 'high', 'low']
        if 'volume' in df.columns:
            base_columns.append('volume')
        df = add_lagged_features(df, base_columns, lags=[1, 2, 3, 5])
        
        # Rolling statistics
        df = add_rolling_statistics(df, ['close'], windows=[5, 20, 50])
        
        # Remove NaN
        df = df.dropna()
        print(f"üìà Dataset final: {df.shape}")
        
        # Prepara features
        exclude_columns = ['id', 'created_at', 'updated_at', 'timestamp']
        feature_columns = [col for col in df.columns if col not in exclude_columns]
        
        # Sele√ß√£o otimizada de features para M1 Max
        if len(feature_columns) > 50:  # Limite maior para M1 Max
            print("üéØ Otimizando features para M1 Max...")
            from sklearn.feature_selection import SelectKBest, mutual_info_regression
            
            X_temp = df[feature_columns].values
            y_temp = df['close'].values
            
            selector = SelectKBest(score_func=mutual_info_regression, k=50)
            X_selected = selector.fit_transform(X_temp, y_temp)
            feature_columns = [feature_columns[i] for i in range(len(feature_columns)) if selector.get_support()[i]]
            print(f"üéØ Selecionadas {len(feature_columns)} features otimizadas")
        
        # Prepara dados
        data = df[feature_columns].values.astype(np.float32)  # float32 para M1 Max
        target_col_idx = feature_columns.index('close')
        
        # Normaliza√ß√£o
        from sklearn.preprocessing import MinMaxScaler
        scaler = MinMaxScaler()
        data_scaled = scaler.fit_transform(data)
        
        # Cria sequ√™ncias
        def create_sequences_m1_max(data, target_col_idx, seq_length):
            X, y = [], []
            for i in range(seq_length, len(data)):
                X.append(data[i-seq_length:i])
                y.append(data[i, target_col_idx])
            return np.array(X, dtype=np.float32), np.array(y, dtype=np.float32)
        
        seq_length = optimal_config['seq_length']
        X, y = create_sequences_m1_max(data_scaled, target_col_idx, seq_length)
        
        # Divis√£o treino/teste
        split_idx = int(len(X) * 0.85)  # 85% treino para M1 Max
        X_train, X_test = X[:split_idx], X[split_idx:]
        y_train, y_test = y[:split_idx], y[split_idx:]
        
        print(f"üìä Treino: {X_train.shape}, Teste: {X_test.shape}")
        
        # Configura√ß√£o LSTM M1 Max
        lstm_config = LSTM_CONFIG_M1_MAX.copy()
        lstm_config.update({
            'epochs': optimal_config['lstm_epochs'],
            'batch_size': optimal_config['batch_size'],
            'force_gpu': optimal_config['use_gpu']
        })
        
        print(f"\nüß† === TREINANDO LSTM M1 MAX ===")
        print(f"‚öôÔ∏è Configura√ß√£o:")
        print(f"   ‚Ä¢ Epochs: {lstm_config['epochs']}")
        print(f"   ‚Ä¢ Batch Size: {lstm_config['batch_size']}")
        print(f"   ‚Ä¢ Sequence Length: {seq_length}")
        print(f"   ‚Ä¢ GPU: {gpu_available}")
        print(f"   ‚Ä¢ Features: {len(feature_columns)}")
        
        # Importa fun√ß√£o otimizada
        try:
            from main_advanced import train_advanced_lstm_m1_max
            
            # Define GPU_AVAILABLE baseado na detec√ß√£o
            gpu_available_for_training = gpu_available
            
            # Treinamento
            lstm_start = time.time()
            
            # Adiciona GPU_AVAILABLE ao contexto global temporariamente
            import main_advanced
            main_advanced.GPU_AVAILABLE = gpu_available_for_training
            
            lstm_model, history = train_advanced_lstm_m1_max(X_train, y_train, X_test, y_test, lstm_config)
            lstm_time = time.time() - lstm_start
            
        except Exception as e:
            print(f"‚ùå Erro importando fun√ß√£o otimizada: {e}")
            print("üîÑ Usando fun√ß√£o padr√£o...")
            
            # Fallback para fun√ß√£o padr√£o
            from main_advanced import train_advanced_lstm
            import main_advanced
            main_advanced.GPU_AVAILABLE = gpu_available_for_training
            
            lstm_start = time.time()
            lstm_model, history = train_advanced_lstm(X_train, y_train, X_test, y_test, lstm_config)
            lstm_time = time.time() - lstm_start
        
        if lstm_model is not None:
            print(f"‚úÖ LSTM treinado em {lstm_time:.1f}s ({lstm_time/60:.1f} min)")
            
            # Previs√µes
            print("üîÆ Fazendo previs√µes...")
            lstm_pred = lstm_model.predict(X_test, verbose=0)
            
            # Desnormaliza
            lstm_pred_full = np.zeros((len(lstm_pred), len(feature_columns)))
            lstm_pred_full[:, target_col_idx] = lstm_pred.flatten()
            lstm_pred_rescaled = scaler.inverse_transform(lstm_pred_full)[:, target_col_idx]
            
            y_test_full = np.zeros((len(y_test), len(feature_columns)))
            y_test_full[:, target_col_idx] = y_test
            y_test_rescaled = scaler.inverse_transform(y_test_full)[:, target_col_idx]
            
            # M√©tricas
            from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
            rmse = np.sqrt(mean_squared_error(y_test_rescaled, lstm_pred_rescaled))
            mae = mean_absolute_error(y_test_rescaled, lstm_pred_rescaled)
            r2 = r2_score(y_test_rescaled, lstm_pred_rescaled)
            
            print(f"\nüìä === RESULTADOS M1 MAX ===")
            print(f"üéØ RMSE: {rmse:.4f}")
            print(f"üìè MAE: {mae:.4f}")
            print(f"üìà R¬≤: {r2:.4f}")
            
            # Pr√≥xima previs√£o
            last_sequence = data_scaled[-seq_length:].reshape(1, seq_length, -1)
            next_pred = lstm_model.predict(last_sequence, verbose=0)[0, 0]
            
            next_pred_full = np.zeros((1, len(feature_columns)))
            next_pred_full[0, target_col_idx] = next_pred
            next_pred_rescaled = scaler.inverse_transform(next_pred_full)[0, target_col_idx]
            
            print(f"üîÆ Pr√≥xima previs√£o: {next_pred_rescaled:.2f}")
            
            # Salva modelo
            print("\nüíæ Salvando modelo M1 Max...")
            import os
            os.makedirs('models', exist_ok=True)
            lstm_model.save('models/lstm_m1_max_optimized.h5')
            print("‚úÖ Modelo salvo em: models/lstm_m1_max_optimized.h5")
        
        # Tempo total
        total_time = time.time() - start_time
        print(f"\n‚è±Ô∏è === PERFORMANCE M1 MAX ===")
        print(f"‚è±Ô∏è Tempo total: {total_time:.1f}s ({total_time/60:.1f} min)")
        print(f"üöÄ LSTM: {lstm_time:.1f}s")
        print(f"üí™ Aproveitamento M1 Max: {'GPU Metal' if gpu_available else 'CPU 10-cores'}")
        print(f"üìä Registros/segundo: {data_size/total_time:.0f}")
        
        if gpu_available:
            print(f"üéØ Speedup estimado vs CPU: 5-10x")
        else:
            print(f"üéØ Speedup vs configura√ß√£o original: 3-5x")
        
        db.disconnect()
        
        return {
            'model': lstm_model,
            'history': history,
            'metrics': {'rmse': rmse, 'mae': mae, 'r2': r2},
            'predictions': {'next': next_pred_rescaled},
            'performance': {
                'total_time': total_time,
                'lstm_time': lstm_time,
                'gpu_used': gpu_available,
                'records_per_second': data_size/total_time
            }
        }
        
    except Exception as e:
        print(f"‚ùå Erro na execu√ß√£o M1 Max: {e}")
        return None

if __name__ == "__main__":
    result = run_m1_max_optimized()
    
    if result:
        print("\nüèÜ === EXECU√á√ÉO M1 MAX CONCLU√çDA ===")
        print("‚úÖ Modelo treinado com sucesso")
        print("üíæ Arquivos salvos em: models/")
        print("üöÄ Performance otimizada para M1 Max")
    else:
        print("\n‚ùå === FALHA NA EXECU√á√ÉO ===")
        print("üîß Verifique configura√ß√µes e depend√™ncias")
